{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Scoring – German Credit Data\n",
    "Production-ready notebook with WoE, Logistic Regression, Threshold Optimization, and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import scorecardpy as sc\n",
    "\n",
    "# ------------------------------\n",
    "# 1️⃣ Load Data\n",
    "# ------------------------------\n",
    "col_names = [\n",
    "    \"account_status\",\"duration\",\"credit_history\",\"purpose\",\n",
    "    \"credit_amount\",\"savings\",\"employment\",\"installment_rate\",\n",
    "    \"personal_status\",\"guarantors\",\"residence\",\"property\",\n",
    "    \"age\",\"other_installments\",\"housing\",\"credit_cards\",\n",
    "    \"job\",\"dependents\",\"phone\",\"foreign_worker\",\"class\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"german.data\", sep=\" \", header=None, names=col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# 2️⃣ Data Sanity Checks\n",
    "# ------------------------------\n",
    "assert (df['duration'] > 0).all(), 'Duration must be positive'\n",
    "assert (df['credit_amount'] > 0).all(), 'Credit amount must be positive'\n",
    "assert (df['age'] > 0).all(), 'Age must be positive'\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# 3️⃣ Data Preparation - WoE\n",
    "# ------------------------------\n",
    "bins = sc.woebin(df, y='class')\n",
    "df_woe = sc.woebin_ply(df, bins)\n",
    "\n",
    "# Keep WoE columns + target\n",
    "woe_cols = [col for col in df_woe.columns if '_woe' in col]\n",
    "data_model = df_woe[woe_cols + ['class']]\n",
    "\n",
    "# Feature importance (IV)\n",
    "iv = sc.woebin_iv(bins).sort_values('info_value', ascending=False)\n",
    "iv[['variable','info_value']]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# 4️⃣ Train/Test Split\n",
    "# ------------------------------\n",
    "X = data_model.drop(columns=['class'])\n",
    "y = (data_model['class'] == 2).astype(int)  # 1=Bad, 0=Good\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# 5️⃣ Logistic Regression Model\n",
    "# ------------------------------\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_proba = lr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# 6️⃣ Evaluation BEFORE Threshold Optimization\n",
    "# ------------------------------\n",
    "y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
    "cm_default = confusion_matrix(y_test, y_pred_default)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_default, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Pred Good','Pred Bad'],\n",
    "            yticklabels=['Actual Good','Actual Bad'])\n",
    "plt.title('Confusion Matrix (Threshold=0.5)')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred_default, target_names=['Good','Bad']))\n",
    "\n",
    "roc_auc_default = roc_auc_score(y_test, y_pred_proba)\n",
    "gini_default = 2*roc_auc_default-1\n",
    "print(f'ROC-AUC: {roc_auc_default:.3f}')\n",
    "print(f'Gini Coefficient: {gini_default:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# 7️⃣ Threshold Optimization (Cost-Sensitive)\n",
    "# ------------------------------\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "costs = []\n",
    "for t in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= t).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred_thresh)\n",
    "    total_cost = cm[0,1]*1 + cm[1,0]*5  # Good->Bad=1, Bad->Good=5\n",
    "    costs.append(total_cost)\n",
    "\n",
    "optimal_idx = np.argmin(costs)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "min_cost = costs[optimal_idx]\n",
    "\n",
    "print(f'Optimal Threshold: {optimal_threshold:.2f}')\n",
    "print(f'Minimum Total Misclassification Cost: {min_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# 8️⃣ Evaluation AFTER Threshold Optimization\n",
    "# ------------------------------\n",
    "y_pred_opt = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "cm_opt = confusion_matrix(y_test, y_pred_opt)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_opt, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Pred Good','Pred Bad'],\n",
    "            yticklabels=['Actual Good','Actual Bad'])\n",
    "plt.title(f'Confusion Matrix (Threshold={optimal_threshold:.2f})')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred_opt, target_names=['Good','Bad']))\n",
    "\n",
    "roc_auc_opt = roc_auc_score(y_test, y_pred_proba)\n",
    "gini_opt = 2*roc_auc_opt-1\n",
    "print(f'ROC-AUC: {roc_auc_opt:.3f}')\n",
    "print(f'Gini Coefficient: {gini_opt:.3f}')\n",
    "\n",
    "# KS Statistic\n",
    "df_ks = pd.DataFrame({'y_true': y_test, 'y_prob': y_pred_proba})\n",
    "df_ks = df_ks.sort_values('y_prob', ascending=False)\n",
    "df_ks['cum_good'] = (df_ks['y_true']==0).cumsum() / (df_ks['y_true']==0).sum()\n",
    "df_ks['cum_bad']  = (df_ks['y_true']==1).cumsum() / (df_ks['y_true']==1).sum()\n",
    "ks_stat = max(abs(df_ks['cum_bad'] - df_ks['cum_good']))\n",
    "print(f'KS Statistic: {ks_stat:.3f}')\n",
    "\n",
    "# KS Curve\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(df_ks['cum_good'], label='Cumulative Good')\n",
    "plt.plot(df_ks['cum_bad'], label='Cumulative Bad')\n",
    "plt.axhline(y=df_ks['cum_bad'].iloc[int(optimal_threshold*len(df_ks))],\n",
    "            color='red', linestyle='--', label=f'Optimal Threshold={optimal_threshold:.2f}')\n",
    "plt.title(f'KS Curve (KS={ks_stat:.3f})')\n",
    "plt.xlabel('Sorted observations by predicted probability')\n",
    "plt.ylabel('Cumulative distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
